{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b260223-d7b1-480d-9bb2-febbc7311029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981e8486-033e-4b63-83e2-affd24ff0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/VRA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6502a490-e3c9-4a19-a8ed-5212fe46f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://data_engineer_test_user:8WBNsM8B^?eDpN$q@localhost:5432/data_engineer_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6331a36-99b9-4395-babe-8f3350940b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype={\n",
    "    \"icao_empresa_aerea\": types.VARCHAR(length=3),\n",
    "    \"numero_voo\": types.UnicodeText(),\n",
    "    \"codigo_autorizacao\": types.Unicode(),\n",
    "    \"codigo_tipo_linha\": types.Unicode(),\n",
    "    \"icao_aerodromo_origem\": types.VARCHAR(length=4),\n",
    "    \"icao_aerodromo_destino\": types.VARCHAR(length=4),\n",
    "    \"partida_prevista\": types.DateTime(),\n",
    "    \"partida_real\": types.DateTime(),\n",
    "    \"chegada_prevista\": types.DateTime(),\n",
    "    \"chegada_real\": types.DateTime(),\n",
    "    \"situacao_voo\": types.VARCHAR(length=15),\n",
    "    \"codigo_justificativa\": types.UnicodeText()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b342cc1-2c43-409f-baa9-35a124404032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_files():\n",
    "    files = os.listdir(path)\n",
    "    # pega apenas os arquivos json, ignorando os arquivos de outras extensões\n",
    "    json_files = [file for file in files if file.endswith(\".json\")]\n",
    "    return json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f491f4-844d-4f84-be01-e8225d380dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filename):\n",
    "    with open(f\"{path}{filename}\", 'r', encoding='utf-8-sig') as json_file:\n",
    "        data_json = json.load(json_file)\n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17491b8c-d7ff-4e51-aebb-151adc4b3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_snake_case(key):\n",
    "    # eliminar os caracteres com acento\n",
    "    key_snake = unicodedata.normalize('NFD', key).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    # verifica se existe letra maiúscula e, se antes e depois dela possui numeros ou caracteres em minúsculo, colocando entre '_'\n",
    "    key_snake = re.sub('([a-z0-9A-Z])([A-Z])([a-z0-9])', r'\\1_\\2\\3', key_snake).lower()\n",
    "    return key_snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf26b1db-aaa6-4fec-89b6-1d60384a5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(index_file, json_file):\n",
    "    data_json = read_json_file(json_file)\n",
    "\n",
    "    # normaliza a chave do json em snake_case, retornado json: chave (caracter original) e value (caracter normalizado: snake_case)\n",
    "    data_keys_normalized = {key: to_snake_case(key) for (key) in data_json[0].keys()}\n",
    "\n",
    "    data_json__normalized = []\n",
    "    # normaliza as chaves do json lido para o snake_case\n",
    "    for idx, data in enumerate (data_json):\n",
    "        data_json__normalized.append({data_keys_normalized[key]: value for (key, value) in data.items()})\n",
    "\n",
    "    # transforma o json para Dataframe, para utilizar a função do pandas para carregar os dados no banco\n",
    "    df_data = pd.json_normalize(data_json__normalized)\n",
    "\n",
    "    # caso seja o primeiro arquivo lido, apaga a tabela e cria um nova\n",
    "    if_exists_type = 'replace' if index_file == 0 else 'append'\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        df_data.to_sql(\n",
    "            name='vra',\n",
    "            con=conn,\n",
    "            schema='data_engineer',\n",
    "            index=False,\n",
    "            if_exists=if_exists_type,\n",
    "            dtype=dtype\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1622c077-2ca0-412b-9f28-d1b110b08103",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = get_json_files()\n",
    "\n",
    "for idx, json_file in enumerate (json_files):\n",
    "    execute(idx, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
